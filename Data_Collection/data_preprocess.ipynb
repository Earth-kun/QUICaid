{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data transformation\n",
    "import pandas as pd            \n",
    "# For statistical analysis\n",
    "import statistics as stat\n",
    "# For ASN lookup\n",
    "import pyasn\n",
    "asndb = pyasn.pyasn('ipasn_20140513.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input csv\n",
    "input_file = \"./benign_flow/yt_test/test10.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "column_names = [\"DURATION\", \"SRC_IP\", \"DST_IP\", \"SRC_PORT\", \"DST_PORT\", \"QUIC_VERSION\", \"BYTES\", \"PROTOCOL\"]\n",
    "df.columns = column_names\n",
    "\n",
    "# delete protocol column\n",
    "df = df.drop(\"PROTOCOL\", axis=1)\n",
    "\n",
    "df[\"BYTES\"] = pd.to_numeric(df[\"BYTES\"], errors='coerce').fillna(0)\n",
    "#df[\"DURATION\"] = df[\"DURATION\"] - df[\"DURATION\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set source IP, web service category, and label\n",
    "ipsrc = \"10.10.3.10\"\n",
    "cat = \"Streaming\"\n",
    "label = \"0\"\n",
    "\n",
    "# determine the destination port and QUIC version\n",
    "\n",
    "\n",
    "# initialize the interpacket variables\n",
    "flow = []\n",
    "arr_fwd_bytes = []\n",
    "arr_rev_bytes = []\n",
    "arr_fwd_iat = []\n",
    "arr_rev_iat = []\n",
    "arr_port = []\n",
    "arr_asn = []\n",
    "arr_ver = []\n",
    "fwd_pkt = 0\n",
    "fwd_bytes = 0.0\n",
    "rev_pkt = 0\n",
    "rev_bytes = 0.0\n",
    "init_dur = 0.0\n",
    "dur = 0.0\n",
    "fwd_dur = 0.0\n",
    "rev_dur = 0.0\n",
    "ctr = 0\n",
    "\n",
    "for index, value in df['SRC_IP'].iteritems():\n",
    "    if value == ipsrc and ctr < 29:\n",
    "        if index == 0:\n",
    "            init_dur = df['DURATION'][index]\n",
    "        else:\n",
    "            fwd_dur += df['DURATION'][index] - init_dur\n",
    "            arr_fwd_iat.append(df['DURATION'][index] - init_dur)\n",
    "        ctr += 1\n",
    "        arr_port.append(df['DST_PORT'][index])\n",
    "        arr_asn.append(asndb.lookup(df['DST_IP'][index])[0])\n",
    "        arr_ver.append(df['QUIC_VERSION'][index])\n",
    "        fwd_pkt += 1\n",
    "        fwd_bytes += df['BYTES'][index]\n",
    "        arr_fwd_bytes.append(df['BYTES'][index])\n",
    "    elif value != ipsrc and ctr < 29:\n",
    "        if index == 0:\n",
    "            init_dur = df['DURATION'][index]\n",
    "        else:\n",
    "            rev_dur += df['DURATION'][index] - init_dur\n",
    "            arr_rev_iat.append(df['DURATION'][index] - init_dur)\n",
    "        ctr += 1\n",
    "        arr_port.append(df['SRC_PORT'][index])\n",
    "        arr_asn.append(asndb.lookup(df['SRC_IP'][index])[0])\n",
    "        arr_ver.append(df['QUIC_VERSION'][index])\n",
    "        rev_pkt += 1\n",
    "        rev_bytes += df['BYTES'][index]\n",
    "        arr_rev_bytes.append(df['BYTES'][index])\n",
    "    elif ctr == 29 or index == len(df['SRC_IP']) - 1:\n",
    "        if value == ipsrc:\n",
    "            fwd_dur += df['DURATION'][index] - init_dur\n",
    "            arr_fwd_iat.append(df['DURATION'][index] - init_dur)\n",
    "            arr_port.append(df['DST_PORT'][index])\n",
    "            arr_asn.append(asndb.lookup(df['DST_IP'][index])[0])\n",
    "            arr_ver.append(df['QUIC_VERSION'][index])\n",
    "            fwd_pkt += 1\n",
    "            fwd_bytes += df['BYTES'][index]\n",
    "            arr_fwd_bytes.append(df['BYTES'][index])\n",
    "        else:\n",
    "            rev_dur += df['DURATION'][index] - init_dur\n",
    "            arr_rev_iat.append(df['DURATION'][index] - init_dur)\n",
    "            arr_port.append(df['SRC_PORT'][index])\n",
    "            arr_asn.append(asndb.lookup(df['SRC_IP'][index])[0])\n",
    "            arr_ver.append(df['QUIC_VERSION'][index])\n",
    "            rev_pkt += 1\n",
    "            rev_bytes += df['BYTES'][index]\n",
    "            arr_rev_bytes.append(df['BYTES'][index])\n",
    "\n",
    "        dst_port = stat.mode(arr_port)\n",
    "        dst_asn = stat.mode([x for x in arr_asn if isinstance(x, int)])\n",
    "        quic_ver = stat.mode(arr_ver)\n",
    "        \n",
    "        new_quic_ver = [x.strip() for x in quic_ver.split(',')]\n",
    "        # Convert each hex value to integer\n",
    "        temp = []\n",
    "        for hex_val in new_quic_ver:\n",
    "            # Verify format\n",
    "            if not hex_val.startswith('0x'):\n",
    "                continue\n",
    "            # Convert to integer\n",
    "            num = int(hex_val, 16)\n",
    "            temp.append(num)\n",
    "        quic_ver = max(temp)\n",
    "        \n",
    "        dur -= df['DURATION'][index]\n",
    "        trips = ctr + 1\n",
    "        ratio = fwd_pkt / rev_pkt\n",
    "        tot_pkt = fwd_pkt + rev_pkt\n",
    "        tot_bytes = fwd_bytes + rev_bytes\n",
    "        flow_pkt = tot_pkt / dur\n",
    "        flow_bytes = tot_bytes / dur\n",
    "        max_bytes = max(fwd_bytes + rev_bytes)\n",
    "        min_bytes = min(fwd_bytes + rev_bytes)\n",
    "        ave_bytes = stat.mean(fwd_bytes + rev_bytes)\n",
    "        std_bytes = stat.stdev(fwd_bytes + rev_bytes)\n",
    "        var_bytes = stat.variance(fwd_bytes + rev_bytes)\n",
    "        max_fwd_bytes = max(arr_fwd_bytes)\n",
    "        min_fwd_bytes = min(arr_fwd_bytes)\n",
    "        ave_fwd_bytes = stat.mean(arr_fwd_bytes)\n",
    "        std_fwd_bytes = stat.stdev(arr_fwd_bytes)\n",
    "        var_fwd_bytes = stat.variance(arr_fwd_bytes)\n",
    "        max_rev_bytes = max(arr_rev_bytes)\n",
    "        min_rev_bytes = min(arr_rev_bytes)\n",
    "        ave_rev_bytes = stat.mean(arr_rev_bytes)\n",
    "        std_rev_bytes = stat.stdev(arr_rev_bytes)\n",
    "        var_rev_bytes = stat.variance(arr_rev_bytes)\n",
    "        max_iat = max(arr_fwd_iat + arr_rev_iat)\n",
    "        min_iat = min(arr_fwd_iat + arr_rev_iat)\n",
    "        ave_iat = stat.mean(arr_fwd_iat + arr_rev_iat)\n",
    "        std_iat = stat.stdev(arr_fwd_iat + arr_rev_iat)\n",
    "        var_iat = stat.variance(arr_fwd_iat + arr_rev_iat)\n",
    "        max_fwd_iat = max(arr_fwd_iat)\n",
    "        min_fwd_iat = min(arr_fwd_iat)\n",
    "        ave_fwd_iat = stat.mean(arr_fwd_iat)\n",
    "        std_fwd_iat = stat.stdev(arr_fwd_iat)\n",
    "        var_fwd_iat = stat.variance(arr_fwd_iat)\n",
    "        max_rev_iat = max(arr_rev_iat)\n",
    "        min_rev_iat = min(arr_rev_iat)\n",
    "        ave_rev_iat = stat.mean(arr_rev_iat)\n",
    "        std_rev_iat = stat.stdev(arr_rev_iat)\n",
    "        var_rev_iat = stat.variance(arr_rev_iat)\n",
    "        ctr = 0\n",
    "        \n",
    "        flow.append([dst_port, dst_asn, quic_ver, dur, cat, trips, ratio, flow_pkt, flow_bytes, tot_pkt, tot_bytes, max_bytes, min_bytes, ave_bytes, std_bytes, var_bytes, fwd_pkt, fwd_bytes, max_fwd_bytes, min_fwd_bytes, ave_fwd_bytes, std_fwd_bytes, var_fwd_bytes, rev_pkt, rev_bytes, max_rev_bytes, min_rev_bytes, ave_rev_bytes, std_rev_bytes, var_rev_bytes, max_iat, min_iat, ave_iat, std_iat, var_iat, fwd_dur, max_fwd_iat, min_fwd_iat, ave_fwd_iat, std_fwd_iat, var_fwd_iat, rev_dur, max_rev_iat, min_rev_iat, ave_rev_iat, std_rev_iat, var_rev_iat, label])\n",
    "\n",
    "        arr_fwd_bytes = []\n",
    "        arr_rev_bytes = []\n",
    "        arr_fwd_iat = []\n",
    "        arr_rev_iat = []\n",
    "        arr_port = []\n",
    "        arr_asn = []\n",
    "        arr_ver = []\n",
    "        fwd_pkt = 0\n",
    "        fwd_bytes = 0.0\n",
    "        rev_pkt = 0\n",
    "        rev_bytes = 0.0\n",
    "        init_dur = 0.0\n",
    "        dur = 0.0\n",
    "        fwd_dur = 0.0\n",
    "        rev_dur = 0.0\n",
    "        ctr = 0\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in flow:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the existing CSV file\n",
    "file_path = \"./benign_flow/benign.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Append each item in the flow list as a new row in the DataFrame\n",
    "for item in flow:\n",
    "    df.loc[len(df)] = item\n",
    "\n",
    "# Write the updated DataFrame back to the CSV file\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to a new CSV file\n",
    "output_file = \"./benign_flow/filtered_output.csv\"\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source IP\n",
    "ipsrc = df[\"SRC_IP\"].iloc[0]\n",
    "portsrc = df[\"SRC_PORT\"].iloc[0]\n",
    "cat = \"Streaming\"\n",
    "\n",
    "flow = []\n",
    "\n",
    "df[\"true_dest\"] = df.apply(lambda row: row[\"DST_IP\"] if row[\"SRC_IP\"] == ipsrc else row[\"SRC_IP\"], axis=1)\n",
    "df[\"group\"] = (df[\"true_dest\"] != df[\"true_dest\"].shift()).cumsum()\n",
    "\n",
    "for group, group_df in df.groupby(\"group\"):\n",
    "    num_subgroups = (len(group_df) + 29) // 30\n",
    "    subgroups = [group_df.iloc[i * 30:(i+1) * 30] for i in range(num_subgroups)]\n",
    "    \n",
    "    # print(f\"Group {group}:\")\n",
    "    # print(group_df)\n",
    "\n",
    "    for  subgroup in subgroups:\n",
    "        ppi_dir = []\n",
    "        ipdst = subgroup[\"true_dest\"].iloc[0]  # The unique normalized destination for this subgroup\n",
    "        portdst = subgroup[\"DST_PORT\"].iloc[0] \n",
    "\n",
    "        ppi_time = [0]\n",
    "        ppi_size = [int(subgroup[\"BYTES\"].iloc[0])]\n",
    "        for i in range(1, len(subgroup)):\n",
    "            # Calculate the time difference between consecutive packets\n",
    "            duration = int((subgroup[\"DURATION\"].iloc[i] - subgroup[\"DURATION\"].iloc[i - 1]) * 1000)\n",
    "            ppi_time.append(duration)\n",
    "            ppi_size.append(int(subgroup[\"BYTES\"].iloc[i]))\n",
    "\n",
    "\n",
    "\n",
    "        for _, row in subgroup.iterrows():\n",
    "            if row[\"SRC_IP\"] == ipsrc and row[\"DST_IP\"] == ipdst:\n",
    "                ppi_dir.append(1)\n",
    "            elif row[\"SRC_IP\"] == ipdst  and row[\"DST_IP\"] == ipsrc:\n",
    "                ppi_dir.append(-1)\n",
    "            else:\n",
    "                ppi_dir.append(0)\n",
    "\n",
    "            bytes_fromsrc = int(subgroup.loc[(subgroup[\"SRC_IP\"] == ipsrc) & (subgroup[\"DST_IP\"] == ipdst),\"BYTES\"].sum())\n",
    "            bytes_rev = int(subgroup.loc[(subgroup[\"SRC_IP\"] == ipdst) & (subgroup[\"DST_IP\"] == ipsrc),\"BYTES\"].sum())\n",
    "            packets = int(subgroup.loc[(subgroup[\"SRC_IP\"] == ipsrc) & (subgroup[\"DST_IP\"] == ipdst),\"BYTES\"].count())\n",
    "            packets_rev = int(subgroup.loc[(subgroup[\"SRC_IP\"] == ipdst) & (subgroup[\"DST_IP\"] == ipsrc),\"BYTES\"].count())\n",
    "            ppi_len = len(ppi_dir)\n",
    "\n",
    "            ppi_rtt = 0\n",
    "            in_group = False\n",
    "\n",
    "            # Iterate through the list\n",
    "            for value in ppi_dir:\n",
    "                if value == -1:  # Start or continue a group of -1's\n",
    "                    if not in_group:\n",
    "                        in_group = True  # Beginning of a group\n",
    "                elif value == 1:  # Start or continue a group of 1's\n",
    "                    if not in_group:\n",
    "                        in_group = True  # Beginning of a group\n",
    "                    elif in_group:\n",
    "                        ppi_rtt += 1\n",
    "                        in_group = False  # Reset for the next group\n",
    "\n",
    "            # Handle the case where the list ends with a valid pair\n",
    "            if in_group:\n",
    "                ppi_rtt += 1\n",
    "\n",
    "        # print(\"Subgroup:\")\n",
    "        # print(subgroup)\n",
    "\n",
    "        dur = round(subgroup[\"DURATION\"].max() - subgroup[\"DURATION\"].min(), ndigits=6)\n",
    "\n",
    "        #flow.append([ipsrc, ipdst, asndb.lookup(ipdst)[0], portsrc, portdst, 1, sni, dur, bytes_fromsrc, bytes_rev, packets, packets_rev, ppi_len, ppi_rtt, cat, [ppi_time, ppi_dir, ppi_size]])\n",
    "        flow.append([portdst, asndb.lookup(ipdst)[0], portsrc, portdst, 1, sni, dur, bytes_fromsrc, bytes_rev, packets, packets_rev, ppi_len, ppi_rtt, cat, [ppi_time, ppi_dir, ppi_size]])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
